{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJ7ldduWDeGMlkJh6Asmbj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NNFLgroup31/TemporalModelling-LSTM/blob/master/rnn_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpbqAhDcIjuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import inspect\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from  torch.autograd import Variable\n",
        "import torch.nn.utils.rnn as rnn_utils \n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter as summary\n",
        "import _pickle as pickle\n",
        "import os\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "class Model(nn.Module):\n",
        "  \n",
        "  def __init__(self,device, n_input=9 * 6 + 1, n_classes=23, batch_size=500, max_obs=26,\n",
        "                 n_layers=2, dropout_keep_prob=.5, adam_lr=1e-3, adam_b1=0.9, adam_b2=0.999, adam_eps=1e-8,\n",
        "                 fc_w_stddev=0.1, fc_b_offset=0.1, n_cell_per_input=1, gpu=None):\n",
        "    super(Model,self).__init__()\n",
        "    self.args=inspect.getargvalues(inspect.currentframe()).locals\n",
        "    del self.args[\"self\"]\n",
        "    self.n_classes=n_classes\n",
        "    self.n_layers=n_layers\n",
        "    self.batch_size=batch_size\n",
        "    self.wstd=fc_w_stddev\n",
        "    self.b=fc_b_offset\n",
        "    ##input model###\n",
        "    self.n_rnn_cells = n_rnn_cells = n_cell_per_input * n_input\n",
        "    self.layer1=nn.LSTM(n_input,hidden_size=n_rnn_cells,num_layers=self.n_layers,dropout=dropout_keep_prob,batch_first=True)\n",
        "    # self.layer2=nn.Softmax(dim=1)\n",
        "    self.opt=optim.Adam(self.parameters(),lr=adam_lr,betas=(adam_b1,adam_b2),eps=adam_eps)\n",
        "    self.writer=summary()\n",
        "    self.max_obs=max_obs\n",
        "    self.device=device\n",
        "  def forward(self,X,hidden):\n",
        "    out,hidden=self.layer1(X,hidden)\n",
        "  \n",
        "    out=out.reshape(-1,out.size(2))\n",
        "    W=torch.normal(mean=0,std=self.wstd,size=(int(out.size(1)),self.n_classes))\n",
        "    b=self.b*torch.ones(self.n_classes)\n",
        "    out=torch.matmul(out,W)+b\n",
        "    out=out.reshape(self.batch_size,-1,self.n_classes)\n",
        "    self.out=out\n",
        "    self.hidden=hidden\n",
        "    return out,hidden\n",
        " \n",
        " \n",
        "  def lossf(self,out,target,obs,train=True):\n",
        "    out=nn.functional.softmax(out,dim=2)\n",
        "    out=out.reshape(-1,out.size(2))\n",
        "    self.mask=mask=self._sequence_mask(obs,target.size(1)).to((self.device))\n",
        "  \n",
        "    target=target.reshape(-1,target.size(2))\n",
        "    loss=-target*torch.log(out)\n",
        "    mask=mask.reshape(-1,1)\n",
        "    mask=mask.expand_as(loss)\n",
        "    loss=mask.double()*loss\n",
        "    loss=torch.sum(loss,1)\n",
        "    a=torch.sum(loss>0)\n",
        "    loss=torch.sum(loss)/a\n",
        "    self.total_samples=a\n",
        "    if train:\n",
        "      self.opt.zero_grad()\n",
        "      loss.backward()\n",
        "      self.opt.step()\n",
        "  \n",
        "    self.writer.add_scalar('cross_entropy',loss.item(),None)\n",
        "    return loss\n",
        "  \n",
        "  def repack_hidden(self):\n",
        "      a,b=self.hidden\n",
        "      a=a.detach_()\n",
        "      b=b.detach_()\n",
        "      self.hidden=(a,b)\n",
        "      return self.hidden\n",
        "\n",
        "  def evaluation(self,out,target):\n",
        "    self.probabilities=probs=nn.functional.softmax(out,dim=2)\n",
        "\n",
        "    #Evaluate model\n",
        "    predicted=torch.argmax(out,dim=2)\n",
        "    targets=torch.argmax(target,dim=2)\n",
        "    correct_pred=torch.tensor(predicted==targets,device=None)\n",
        "    mask_correct_pred=torch.bitwise_and(correct_pred,self.mask)\n",
        "    self.accuracy=accuracy=torch.sum(mask_correct_pred.float())/self.total_samples\n",
        "    self.writer.add_scalar('accuracy',accuracy)\n",
        "\n",
        "    self.probs_list=probs_list=torch.reshape(probs,(-1,self.n_classes))\n",
        "    predicted_list=torch.reshape(predicted,(-1,1))\n",
        "    targets_list=torch.reshape(targets,(-1,1))\n",
        "\n",
        "    mask_list=torch.reshape(self.mask,(-1,1))\n",
        "    one_hot_targets=torch.zeros((predicted_list.size(0),self.n_classes),dtype=torch.float32,device=None)\n",
        "    one_hot_targets.scatter_(1,targets_list,1)\n",
        "    scores=torch.masked_select(probs_list,torch.tensor(one_hot_targets==1))\n",
        "\n",
        "    obs_list=torch.arange(0,self.max_obs).expand(self.batch_size,-1)\n",
        "    probs_matrix_mask=mask_list.expand(-1,self.n_classes)\n",
        "    \n",
        "    self.scores=torch.masked_select(probs_list,probs_matrix_mask)\n",
        "    self.targets=torch.masked_select(targets_list,probs_matrix_mask)\n",
        "    \n",
        "\n",
        "    target_=torch.unsqueeze(target,1)\n",
        "    self.writer.add_images('targets',target_,dataformats='NCHW')\n",
        "\n",
        "    probs_=torch.unsqueeze(probs,1)\n",
        "    self.writer.add_images('probabilities',probs_,dataformats='NCHW')\n",
        "\n",
        "    logits_=torch.unsqueeze(out,1)\n",
        "    self.writer.add_images('logits_',target_,dataformats='NCHW')\n",
        "    return None\n",
        "  def _sequence_mask(self,sequence_length, max_len=None):\n",
        "      if max_len is None:\n",
        "          max_len = sequence_length.data.max()\n",
        "      batch_size = sequence_length.size(0)\n",
        "      seq_range = torch.arange(0, max_len ).long()\n",
        "      seq_range_expand = seq_range.unsqueeze(0).expand(batch_size, max_len)\n",
        "      seq_range_expand = Variable(seq_range_expand)\n",
        "      if sequence_length.is_cuda:\n",
        "          seq_range_expand = seq_range_expand.cuda()\n",
        "      seq_length_expand = (sequence_length.unsqueeze(1)\n",
        "                          .expand_as(seq_range_expand))\n",
        "      return seq_range_expand < seq_length_expand\n",
        "\n",
        "\n",
        "    \n",
        "  def intial_hiddenstate(self):\n",
        "     weight = next(self.parameters()).data\n",
        "     return (Variable(weight.new(self.n_layers,self.batch_size, self.n_rnn_cells).zero_()).to(str(self.device)),\n",
        "                Variable(weight.new(self.n_layers,self.batch_size, self.n_rnn_cells).zero_()).to(str(self.device)))\n",
        "     ###add gpu compatibility\n",
        "        #  if self.hparams.on_gpu:\n",
        "        #     hidden_a = hidden_a.cuda()\n",
        "        #     hidden_b = hidden_b.cuda()\n",
        "\n",
        "        # hidden_a = Variable(hidden_a)\n",
        "        # hidden_b = Variable(hidden_b)\n",
        "\n",
        "def main():\n",
        "      model=Model(device=device)\n",
        "      # path='gdrive/My Drive/lstm/rundir'\n",
        "      # pickle.dump(model.args,open(os.path.join(path,'args.pkl'),\"wb\"))\n",
        "      # open(os.path.join(path, \"args.txt\"), \"w\").write(str(model.args))\n",
        "      #  writer=summary(\"gdrive/My Drive/lstm/rundir\")\n",
        "      #  writer=model.writer\n",
        "      # writer.close()\n",
        "      \n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFBp3a40p0qo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "789c6ce7-1d8c-46b2-cb1d-83b12c0dacf9"
      },
      "source": [
        "!git clone https://github.com/NNFLgroup31/TemporalModelling-LSTM.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TemporalModelling-LSTM'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 9 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}